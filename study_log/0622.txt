0622_월요일

1. virtualbox 5.2.42
	ㄴ windows hosts
2. vagrant 2.2.2
	ㄴ Vagrant_2.2.2_x86_64.msi
3. 설치완료시 C:\HashiCorp\Vagrant 폴더 생성됨

4. cmd로 관리자모드 실행 후 c:\HashiCorp까지 이동

5. vagrant init 실행

6. c:\HashiCorp에 존재하는 Vagrantfile의 모든 내용을 제거하고 다음을 추가한다.

7. 아래 내용
VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|

     config.ssh.insert_key = false
     config.vm.define :nn01 do |nn01_config|
        nn01_config.vm.box = "centos/7"
        nn01_config.vm.hostname = "nn01"
        nn01_config.vm.network "private_network", ip: "192.168.56.101"
        nn01_config.vm.provider :virtualbox do |vb|
            vb.name = "nn01"
            vb.memory = "4096"
        end

     end

    config.vm.define :dn01 do |dn01_config|
        dn01_config.vm.box = "centos/7"
        dn01_config.vm.hostname = "dn01"
        dn01_config.vm.network "private_network", ip: "192.168.56.102"
        dn01_config.vm.provider :virtualbox do |vb|
            vb.name = "dn01"
            vb.memory = "4096"
        end
    end



config.vm.define :dn02 do |dn02_config|
        dn02_config.vm.box = "centos/7"
        dn02_config.vm.hostname = "dn02"
        dn02_config.vm.network "private_network", ip: "192.168.56.103"
        dn02_config.vm.provider :virtualbox do |vb|
            vb.name = "dn02"
            vb.memory = "4096"
        end
    end


end

8. vagrant up 실행

9. vagrant 설치 중 에러 발생시
	ㄴ c->user->VirtualBox VMs에 생긴 폴더, .virtualbox 에 생긴 폴더, HashiCorp .vagrant에 생긴 폴더를 지우고 다시 시도

10. 3개를 하나씩 들어가서 ip addr로 확인하는데 셋 중 가장 밑에껄로 확인하는듯
11. 마우스 잡기
	ㄴ 파일 -> 환경설정 -> 입력 -> 가상머신 -> 호스트 키 조합 -> Ctrl + Alt (둘다 왼쪽)
12. putty 연결
	ㄴ https://putty.ko.softonic.com/
	ㄴ putty-0.70-installer.msi  다운받아 설치
	ㄴ 실행
		ㄴ 192.168.56.101  nn01  [Save]버튼
		ㄴ 192.168.56.102  dn01  [Save]버튼
		ㄴ 192.168.56.103  dn02  [Save]버튼
13. sshd config 수정
[root@nn01 ~]vi /etc/ssh/sshd_config
/Password를 검색한다.
PasswordAuthentication no를
PasswordAuthentication yes로 변경한다.
(63라인은 주석, 65라인을 수정해야됨)
[root@nn01 ~]systemctl restart sshd
putty접속이 가능하다
dn01, dn02에도 같은 작업을 한다.
[root@dn01 ~]vi /etc/ssh/sshd_config
[root@dn01 ~]systemctl restart sshd
[root@dn02 ~]vi /etc/ssh/sshd_config
[root@dn02 ~]systemctl restart sshd
14. putty 접속을 확인한다.
15. mobaxterm 설치
16. mobaxterm 사용
설치 작업을 편리하게 해주는 도구(Putty 세션을 동기화 한다.)
https://mobaxterm.mobatek.net > 왼쪽 메뉴 > download
다운 받아 zip 파일을 푼다
실행하면 Putty의 세션이 자동으로 로드 된다.
왼쪽에 Putty Sessions에 putty 연결이 들어온거 확인하고 하나씩 눌러놓고
MultiExec 을 클릭한다.
17. winscp
Windows용 그래픽 유저 인터페이스 SFTP 및 FTP 클라이언트 프로그램이고 오픈소스 프리웨어입니다.
이 프로그램을 사용하여 로컬 컴퓨터와 원격 컴퓨터 간에 안전하게 파일을 복사할 수 있습니다.
https://winscp.net/eng/download.php
WinSCP-5.15-Setup.exe
18. 패키지 추가
yum update
19. 자주 쓰는 프로그램 설치
yum install telnet svn git nc ntp wget vim net-tools 
20. 방화벽 끄기
systemctl stop firewalld
systemctl disable firewalld
21. vi 에디터 설정 변경
	vi /etc/virc
	shift + g -> 맨 마지막줄로 이동
	o -> 커서의 다음줄에 입력
	set nu -> 입력 후 저장하고 나감
++ backspace로 지워지지 않을 경우(^H^H등의 문자가 나올경우)
	ㄴ ctrl backspace를 누르기
----------------------------------------------------------------------------------------------------
JDK, Hadoop설치
	ㄴ master, slave 역할
		nn01 = Master (NameNode, SecondaryNamenode, ResourceManager)
		dn01 = Slave (DataNode, NodeManager)
		dn02 = Slave (DataNode, NodeManager)
		nn01, dn01, dn02 각각에서 JDK의 압축을 해제하고 설치하고 설정
		mobaTerm으로 반복 동작을 줄일 수 있다.
		모든 사용자를 위한 java를 설치할 예정이니, root 계정으로 로그인한다.
		설치되었는지 확인하기
		[root@nn01 ~]$ which java
1. protobuf 설치
(1) 설치전 필요 툴 ( root 계정에서 )
 $ yum install -y autoconf automake libtool curl gcc-c++ unzip
(2) 다운로드 ( 책마다 버전이 중요하다고 강조하는데 )
# cd /tmp
# wget https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
# tar -zxvf protobuf-2.5.0.tar.gz
# mv protobuf-2.5.0  /opt/
# 이동되었는지 확인
(3) 설치 ( protobuf 폴더로 이동 )
# ./configure
# make                ( 여기서 에러가 발생하면 ./configure에서 안되는 것임 )
# make install
(4) 확인
protoc --version
만일 에러 발생시 lfconfig ( 소문자 엘) 후 다시 protoc --version

2. JDK 8 설치 (nn01,dn01,dn02)
a. cd /tmp
b. yum install -y vim wget unzip          
c. wget --no-check-certificate --no-cookies - --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz
                       ( Local에 이미 다운로드 한 경우 Winscp를 이용하여 업로드 )
d. ls jdk*
e. tar -xvzpf jdk-8u131-linux-x64.tar.gz
f. mkdir -p /opt/jdk/1.8.0_131
g. mv jdk1.8.0_131/* /opt/jdk/1.8.0_131/
g_2. ls -l /opt/jdk
	ㄴ 심볼릭 링크 확인
h. ln -s /opt/jdk/1.8.0_131 /opt/jdk/current
i. 
alternatives --install /usr/bin/java java /opt/jdk/1.8.0_131/bin/java 2
j. 
alternatives --config java
	ㄴ 최소로 설치를 한 상태이기 떄문에 -> 1 입력
alternatives --install /usr/bin/jar jar /opt/jdk/1.8.0_131/bin/jar 2
k.
alternatives --install /usr/bin/jar jar /opt/jdk/1.8.0_131/bin/jar 2
alternatives --install /usr/bin/javac javac /opt/jdk/1.8.0_131/bin/javac 2
alternatives --set jar /opt/jdk/1.8.0_131/bin/jar
alternatives --set javac /opt/jdk/1.8.0_131/bin/javac
l. java -version 확인

3. Hadoop 설치 (nn01 / dn01 / dn02)
a. cd /tmp
b. wget http://apache.tt.co.kr/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz
wget  https://archive.apache.org/dist/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz
c. tar -xvzf hadoop-2.7.7.tar.gz
d. mkdir -p /opt/hadoop/2.7.7
e. mv hadoop-2.7.7/* /opt/hadoop/2.7.7/
f. ln -s /opt/hadoop/2.7.7 /opt/hadoop/current

4. Hadoop 사용자 추가
a. useradd hadoop
b. passwd hadoop   ( 비밀번호도 hadoop 으로 - 비밀번호 입력시는 글자표시 안됨  )
c. chown -R hadoop:hadoop /opt/hadoop/  ( 루트에서 만든 파일의 권한을 hadoop에게 권함)
d. vi /etc/pam.d/su (설정파일 건드릴때는 멀티 풀기)
	ㄴ 10, 11, 12라인 주석처리 (#붙이기)
	ㄴ 설정을 하지 않으면 hadoop계정에서 root계정으로 넘어오질 못함
	ㄴ 설정을 하지 않고 실수로 넘어갔을 경우 logout을 하면 다시 root계정으로 넘어감
e. su - hadoop (환경변수도 같이 넘어감)
	ㄴ 확인만 하고 다시 root로 돌아옴(5번 부분에서 여기서 실수한듯 -> hadoop에서 하는게 맞음)

5. 자바 및 Hadoop 환경 변수 추가 (***** hadoop계정에서 해야되는듯 *****)
( 설정파일 수정할 때는 MultiExe 보다 하나씩 하는 것이 나을 수도 있다 )
a. vi ~/.bash_profile
b. shift + g -> o(커서의 다음줄에 입력) -> 아래 내용 붙이기
	ㄴ 아래 내용 3번째 라인에 current(심볼릭 링크에 연결해둬서 버전 변경시 설정 파일을 안 건드려도 되게 만듬)
	ㄴ 기존 PATH 경로에 추가를 해서 명령어를 다른곳에서도 쓰기 위함

  #### HADOOP 2.7.7 start ############
  PATH=$PATH:$HOME/bin
  export HADOOP_HOME=/opt/hadoop/current
  export PATH=$PATH:$HADOOP_HOME/bin
  export PATH=$PATH:$HADOOP_HOME/sbin
  #### HADOOP 2.7.7end############

  #### JAVA 1.8.0 start#############
  export JAVA_HOME=/opt/jdk/current
  export PATH=$PATH:$JAVA_HOME/bin
  #### JAVA 1.8.0 end##############

c. source ~/.bash_profile 
	ㄴ 쉘 스크립트 적용

9. 자바 및 hadoop 버전 확인
    a. java -version
    b. hadoop version

10. 비밀번호없이 각노드를 접속할 수 있도록 공개키 공유(SSH)
(0) 아래부분은 가상머신에서  직접해야 한다. (*****) -> multi (x)
vi 강제 종료  :q!
vi /etc/hosts (root 권한으로 ) - localhost 꼭 지운다 ( 모든 노드 다 )
3줄 있는 걸 전부 다 지우고 아래 3줄을 그대로 타이핑하면 됨
192.168.56.101 nn01
192.168.56.102 dn01
192.168.56.103 dn02
(1) 키만들기 (Hadoop 계정에서 )
( MultiExec 에서 하면 다른 키값을 생성되는 것을 볼 수 있다 )
su - hadoop 으로 전부 하둡계정으로 전환함

[hadoop@nn01 ~]$ ssh-keygen
[hadoop@dn01 ~]$ ssh-keygen
[hadoop@dn02 ~]$ ssh-keygen
각각 입력하는 부분에서 엔터만 3번친다

(2) 키복사하기 
( 여기서는 MultiExec 풀고 작업 - 각 노드별로 작업)
(***** 자기 자신에게도 복사를 해야 됨 *****)

[hadoop@nn01 ~]$ ssh-copy-id hadoop@dn01
[hadoop@nn01 ~]$ ssh-copy-id hadoop@nn01
[hadoop@nn01 ~]$ ssh-copy-id hadoop@dn02
 
[hadoop@dn01 ~]$ ssh-copy-id hadoop@dn01
[hadoop@dn01 ~]$ ssh-copy-id hadoop@nn01
[hadoop@dn01 ~]$ ssh-copy-id hadoop@dn02

[hadoop@dn02 ~]$ ssh-copy-id hadoop@dn01
[hadoop@dn02 ~]$ ssh-copy-id hadoop@nn01
[hadoop@dn02 ~]$ ssh-copy-id hadoop@dn02
yes >  비밀번호 hadoop
---------------------------------------
****패스워드없이 이동이 가능하다.  ( 나올 때는 exit 또는 logout 으로 나온다 )
[hadoop@nn01 ~]$ ssh dn01
[hadoop@nn01 ~]$ ssh dn02

[hadoop@dn01 ~]$ ssh nn01
[hadoop@dn01 ~]$ ssh dn02

[hadoop@dn02 ~]$ ssh nn01
[hadoop@dn02 ~]$ ssh dn01

*********hadoop설정
nn01에서 하고 dn01, dn02 전송하던가
한 노드씩 같이 하던가 (권장)

12. Hadoop 설정 (-> 모든 노드에서 해야되는듯 )
 ( 설정은 MultiExec를 풀고 각 노드마다 하는 것이 낫다
  또 복사하고 제발 확인하고 다시 열여서 또 확인하자
  우선 nn01에서 작업하자
  )

a. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/core-site.xml

<configuration>
<property>
<name>fs.defaultFS</name>
<value>hdfs://nn01:9000</value>
</property>
</configuration>
-------------------------------------------------------------

b. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/hdfs-site.xml

<configuration>

<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.http-address</name>
<value>nn01:50070</value>
</property>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>nn01:50090</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/home/hadoop/hadoop_data/hdfs/namenode</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/home/hadoop/hadoop_data/hdfs/datanode</value>
</property>
<property>
<name>dfs.namenode.checkpoint.dir</name>
<value>file:/home/hadoop/hadoop_data/hdfs/namesecondary</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>

</configuration>

-------------------------------------------------------------
c. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/yarn-site.xml

<configuration>

<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>nn01:8030</value>
</property>
<property>
<name>yarn.resourcemanager.resource-tracker.address</name>
<value>nn01:8031</value>
</property>
<property>
<name>yarn.resourcemanager.address</name>
<value>nn01:8032</value>
</property>
<property>
<name>yarn.resourcemanager.hostname</name>
<value>nn01</value>
</property>

</configuration>

-------------------------------------------------------------
d. [hadoop@nn01 ~]$ cp /opt/hadoop/current/etc/hadoop/mapred-site.xml.template /opt/hadoop/current/etc/hadoop/mapred-site.xml


e. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/mapred-site.xml

<configuration>

<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
<property>
<name>mapreduce.jobtracker.hosts.exclude.filename</name>
<value>$HADOOP_HOME/etc/hadoop/exclude</value>
</property>
<property>
<name>mapreduce.jobtracker.hosts.filename</name>
<value>$HADOOP_HOME/etc/hadoop/include</value>
</property>

</configuration>

-------------------------------------------------------------
f. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/masters
nn01

-------------------------------------------------------------
g. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/slaves
dn01
dn02

-------------------------------------------------------------
h. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/hadoop-env.sh
# The java implementation to use.
export JAVA_HOME=/opt/jdk/current

ii. [hadoop@nn01 ~]$ vi /opt/hadoop/current/etc/hadoop/yarn-env.sh
# some Java parameters
export JAVA_HOME=/opt/jdk/current

ModaXterm으로 작업하지 않았으면 아래부분 작업으로 해도 된다
=============================================
hadoop설정을 nn01에서하고 dn01과 dn02에 복사 (winscp툴을 이용하거나 scp명령을 이용한다.

혹은
[nn01(root 계정)]
a. [root@nn01 ~]# scp -r /opt/hadoop/* dn01:/opt/hadoop
a. [root@nn01 ~]# scp -r /opt/hadoop/* dn02:/opt/hadoop

[dn01(root 계정)] 심볼릭링크와 소유자를 다시 설정한다.
a. [root@dn01 ~]# rm -rf /opt/hadoop/current
b. [root@dn01 ~]# ln -s /opt/hadoop/2.7.7 /opt/hadoop/current
c. [root@dn01 ~]# chown -R hadoop:hadoop /opt/hadoop/
[dn02(root 계정)] 심볼릭링크와 소유자를 다시 설정한다.
a. [root@dn02 ~]# rm -rf /opt/hadoop/current
b. [root@dn02 ~]# ln -s /opt/hadoop/2.7.7 /opt/hadoop/current
c. [root@dn02 ~]# chown -R hadoop:hadoop /opt/hadoop/
==============================================
[ 확인] ll /opt/hadoop


각노드에서 해야 하니깐 MobaXterm 멀티창 끄기

14. Hadoop namenode 디렉토리 생성 (nn01 : Namenode)
 a. mkdir -p ~/hadoop_data/hdfs/namenode
 b. mkdir -p ~/hadoop_data/hdfs/namesecondary

15. Hadoop datanode 디렉토리 생성 (dn01 : Datanode)
 mkdir -p ~/hadoop_data/hdfs/datanode

Hadoop datanode 디렉토리 생성 (dn02 : Datanode)
mkdir -p ~/hadoop_data/hdfs/datanode

#### 잘못된 16 ->16. (5번에서 하둡계정으로 했었어야함 아니면 su - root)
	ㄴ 문제가 생겼을 경우
		ㄴ chown -R hadoop:hadoop /home/hadoop
16. Namenode 포맷 (nn01)
hadoop namenode -format

17. Daemon 시작 (nn01) - ***** virtualbox 끄기 전에 stop-all.sh 하고 종료하기
a. start-all.sh

18. 서비스 정상 확인
[hadoop@nn01 ~]$ jps
16624 ResourceManager
16883 Jps
16232 NameNode
16462 SecondaryNameNode
 
 
[hadoop@dn01 ~]$ jps
10518 DataNode
10650 NodeManager
10780 Jps
 
[hadoop@dn02 ~]$ jps
7041 DataNode
7141 NodeManager
7271 Jps