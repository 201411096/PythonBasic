0623_화요일


hdfs
	ㄴ hadoop distributed file system
--------------------------------------------------------------------------------
1.
hdfs dfs -ls /
hdfs dfs -mkdir /input
ls /input
	ㄴ /input 디렉토리가 보이지 않음
		ㄴ 하둡위에서 만들어지는 거라 리눅스랑 상관없음
ls /opt/hadoop.current
hdfs dfs -put /opt/hadoop/current/*.txt /input
	ㄴ /opt/hadoop/current의 txt파일들을 hadoop의 input 디렉토리로 올려둠
		ㄴ 알아서 분산처리가 시작됨
--------------------------------------------------------------------------------
2. 하둡 예제
	ㄴ references 개념 하둡 참고
a) 프로젝트 생성
	ㄴ group id
		ㄴ com.kosmo
	ㄴ artifact id
		ㄴ lab1
	ㄴ packaging
		ㄴ jar
	ㄴ map, reduce 부분만 코딩을 하면 됨
b) run as -> maven install 2번
	ㄴ target 에 생성된 lab1-0.0.1-SNAPSHOT.jar 파일이 실행파일
c)winscp에 추가
	ㄴ 192.168.56.101
	ㄴ hadoop hadoop
	ㄴ 저장 -> 암호저장
	ㄴ winscp에서 source폴더를 만들어둠
	ㄴ lab1-0.0.1-SNAPSHOT.jar 파일이름을 lab1.jar 파일로 변경하고 source폴더로 이동
	ㄴ ls 했을 경우 lab1.jar파일이 보임
	ㄴ mkdir temp
	ㄴ vi temp/mydata.txt
		ㄴ 영단어 3개짜리 4줄 입력
	ㄴ hdfs dfs -mkdir -p /input/data
	ㄴ hdfs dfs -ls /input
	ㄴ hdfs dfs -put /home/hadoop/temp/mydata.txt /input/data
	ㄴ hdfs dfs -ls /input/data
	ㄴ yarn jar /home/hadoop/source/lab1.jar
		ㄴ pom.xml에 클래스명을 달았으면 메인함수가 포함된 클래스를 기술하지 않고 이런식으로 돌리면 됬었음
	ㄴ yarn jar /home/hadoop/source/lab1.jar sample.WordCount /input/data/mydata.txt /output/wordcount
	ㄴ map 100% reduce 100%면 성공
	ㄴ hdfs dfs -ls /output/wordcount
	ㄴ hdfs dfs -cat /output/wordcount/part-r-00000
d) 10k 파일을 hadoop/temp로 이동
	ㄴ HDFS 에 /input/data/wiki 폴더 생성
		ㄴ hdfs dfs -ls /input/data
		ㄴ hdfs dfs -mkdir -p /input/data/wiki
		ㄴ hdfs dfs -ls /input/data
		ㄴ hdfs dfs -put /home/hadoop/temp/10K.ID.CONTENTS /input/data/wiki
		ㄴ hdfs dfs -ls /input/data/wiki
	ㄴ 10K.ID.CONTENTS 파일을 /input/data/wiki 폴더에 저장하기
e) matrix.txt를 hadoop의 /input/data로 이동
...
--------------------------------------------------------------------------------
flume 설치
	ㄴ dn01 노드의 root계정 (에코시스템은 대부분 dn01 root에 설치)
--------------------------------------------------------------------------------
history log
    1  su - root
    2  logout
    3  exit
    4  vi ~/.bash_profile
    5  source ~/.bash_profile
    6  start-all.sh
    7  jps
    8  clear
    9  hdfs
   10  hdfs dfs -ls
   11  hdfs dfs -mkdir /input
   12  hdfs dfs -ls
   13  hdfs dfs -ls /
   14  ls /opt/hadoop/current
   15  hdfs dfs -put /opt/hadoop/current/*.txt /input
   16  hdfs dfs -ls /input
   17  ls source
   18  ls
   19  mkdir temp
   20  vi temp/mydata.txt
   21  pwd
   22  ls -l
   23  pwd
   24  ls -l
   25  ls temp
   26  hdfs dfs -mkdir -p /input/data
   27  hdfs dfs -ls /input
   28  hdfs dfs -put /home/hadoop/temp/mydata.txt /input/data
   29  hdfs dfs -ls /input/data
   30  yarn jar /home/hadoop/source/lab1.jar sample.WordCount /input/data/mydata.txt /output/wordcount
   31  hdfs dfs -ls /output/wordcount
   32  hdfs dfs -cat /output/wordcount/part-r-00000
   33  ls -l temp
   34  hdfs dfs -ls
   35  hdfs dfs -mkdir -p /input/data/wiki
   36  hdfs dfs -ls /input/data
   37  hdfs dfs -put /home/hadoop/temp/10K.ID.CONTENTS /input/data/wiki
   38  hdfs dfs -ls /input/data/wiki
   39*
   40  hdfs dfs -ls /output/wordcount2
   41  hdfs dfs -cat /output/wordcount2/part-r-00000 | head -100
   42  ls -l
   43  ls -l temp
   44  hdfs dfs -put /home/hadoop/temp/matrix.txt /input/data
   45  hdfs dfs -ls /input/data
   46  yarn jar /home/hadoop/source/lab1.jar sample3.MatrixProduct /input/data/matrix.txt /output/matrixproduct
   47  hdfs dfs -ls /output
   48  hdfs dfs -ls /output/matrixproduct
   49  hdfs dfs -ls /output/matrixproduct/part-r-00000
   50  hdfs dfs -cat /output/matrixproduct/part-r-00000
   51  history
dn01---
    1  su - root
    2  logout
    3  exit
    4  vi ~/.bash_profile
    5  source ~/.bash_profile
    6  ls -l /opt/flume
    7*
    8  source ~/.bash_profile
    9  vi ~/.bash_profile
   10  cd $FLUME_HOME/conf
   11  ls -l
   12  cat flume-conf.properties.template
   13  cp flume-conf.properties.template flume-conf.properties
   14  ls -l
   15  history
