{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[도서]  [데이터실무분석 with파이썬 예제](https://wikibook.co.kr/playwithdata/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 인스타그램 크롤링 \n",
    "\n",
    "### (1) selenium 설치 \n",
    "   \n",
    "    + pip install selenium\n",
    "    \n",
    "    + 웹드라이버 다운로드\n",
    "        http://chromedriver.chromium.org/downloads\n",
    "        chromedirver_win32.zip 파일 다운로드 받고 압축풀기\n",
    "\n",
    "        설치된 크롬 버전과 맞는 버전을 다운로드 해야 한다.\n",
    "        \n",
    "        \n",
    "---        \n",
    "[참고] 사이트 변경으로 인해 데이타를 못 가져올 수도 있다        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 인스타그램 검색 결과 URL을 만들어서 접속하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-1 인스타그램 검색결과 URL을 만드는 함수\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriverpath = 'D:/python-workspace/PythonBasic/webdriver/chromedriver.exe' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기\n",
    "from selenium import webdriver\n",
    "\n",
    "# 본인의 webdriver 설치 경로 맞추기\n",
    "#driver = webdriver.Chrome(\"D:/MyClass/Python/eAnalysisExample/2_제주맛집_크롤링_지도/webdriver/chromedriver.exe\")   \n",
    "driver = webdriver.Chrome(webdriverpath)   \n",
    "\n",
    "word = \"제주도맛집\"\n",
    "url = insta_searching(word)\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 첫 번째 게시글 열기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-3 HTML에서 첫번째 게시글 찾아 클릭하기\n",
    "def select_first(driver):\n",
    "    \n",
    "    driver.implicitly_wait(10) # 로딩 속도 때문에 클릭이벤트를 못하기에 추가 ( 상황에 따라 실행되었다 안되었다 함 )\n",
    "    \n",
    "    first = driver.find_element_by_css_selector(\"div._9AhH0\")\n",
    "    first.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 게시글 정보 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-4 게시글 정보 가져오기\n",
    "import re\n",
    "\n",
    "def get_content(driver):\n",
    "    # ① 현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    # ② 본문 내용 가져오기\n",
    "    try:\n",
    "        content = soup.select('div.C4VMK > span')[0].text\n",
    "    except:\n",
    "        content = ' '\n",
    "    # ③ 본문 내용에서 해시태그 가져오기(정규식 활용)\n",
    "    tags = re.findall(r'#[^\\s#,\\\\]+', content)  \n",
    "    # ④ 작성일자 정보 가져오기\n",
    "    date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10]\n",
    "    print('get_content 확인', date)\n",
    "    # ⑤ 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('div.Nm9Fw > button')[0].text[4:-1]   \n",
    "    except:\n",
    "        like = 0\n",
    "    # ⑥ 위치정보 가져오기\n",
    "    try: \n",
    "        place = soup.select('div.M30cS')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "    # ⑦ 수집한 정보 저장하기\n",
    "    data = [content, date, like, place, tags]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 다음 게시글 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-5 다음 게시글 열기\n",
    "def move_next(driver):\n",
    "\n",
    "    driver.implicitly_wait(10) # 로딩 속도 때문에 클릭이벤트를 못하기에 추가 ( 상황에 따라 실행되었다 안되었다 함 )\n",
    "    \n",
    "    right = driver.find_element_by_css_selector ('a.coreSpriteRightPaginationArrow')\n",
    "    right.click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 여러 게시글 정보 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "#------------------------------------------------------------------------------------\n",
    "def readp():\n",
    "    f = open(\"D:/python-workspace/PythonBasic/webdriver/a.txt\")\n",
    "    a = f.readline()\n",
    "    return a\n",
    "def login(driver):\n",
    "    driver.find_elements_by_css_selector('label.f0n8F > input')[0].send_keys('010-3303-1995')\n",
    "    driver.find_elements_by_css_selector('label.f0n8F > input')[1].send_keys(readp())\n",
    "    driver.find_elements_by_css_selector('button.sqdOP > div.Igw0E')[0].click()\n",
    "    time.sleep(3)\n",
    "    driver.find_elements_by_css_selector('button.sqdOP')[0].click()\n",
    "    \n",
    "# ① 크롬 브라우저 열기\n",
    "driver = webdriver.Chrome(webdriverpath) # 테스트 하고 \n",
    "# ② 인스타그램 검색페이지 URL 만들기\n",
    "word = \"제주도맛집\"    #검색어\n",
    "url = insta_searching(word)\n",
    "\n",
    "# ③ 검색페이지 접속하기\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "#------------------------------------------------------------------------------------\n",
    "select_first(driver)\n",
    "login(driver)\n",
    "select_first(driver)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "get_content 확인 2020-07-05\n",
      "get_content 확인 2020-07-06\n",
      "get_content 확인 2020-07-05\n",
      "get_content 확인 2020-07-06\n",
      "get_content 확인 2020-07-06\n",
      "[['올여름은 제주도로 고고~제주갈치왕은 필수😍-여기갈치 요리가 최고로 맛있엉👍-제주산 갈치라 싱싱하고 살도 토실토실~해산물 폭탄으로 들어간 해물탕까지~살살 녹는 갈치요리 찐찐찐~ 맛집 갈치왕!🐟-여기 사장님의 손맛이 끝내주셔서밥 두공기는 기본으로 클리어~통갈치 해물찜과 술은 환상의 짝꿍~💏-🦄제주 풍경 보고~ 해산물, 갈치 요리 먹방하러 갈치왕으로~-@kingfish1190- 업체명 : 갈치왕 본점-주소 : 제주 서귀포시 일주서로 1146-전화 : 064-739-9333-#제주도맛집 #갈치왕#제주도맛집베스트 #제주도맛집추천#제주도맛집투어 #제주도핫플 #갈치맛집 #제주도갈치맛집 #제주갈치 #제주도갈치 #갈치구이맛집 #제주갈치구이 #제주갈치조림 #서귀포맛집추천 #제주가볼만한곳 #조림맛집 #제주도갈치맛집#좋반#좋아요반사#좋아요#좋반테러', '2020-07-05', 0, '', ['#제주도맛집', '#갈치왕', '#제주도맛집베스트', '#제주도맛집추천', '#제주도맛집투어', '#제주도핫플', '#갈치맛집', '#제주도갈치맛집', '#제주갈치', '#제주도갈치', '#갈치구이맛집', '#제주갈치구이', '#제주갈치조림', '#서귀포맛집추천', '#제주가볼만한곳', '#조림맛집', '#제주도갈치맛집', '#좋반', '#좋아요반사', '#좋아요', '#좋반테러']], ['애월카페 망고레이.새콤달콤 맛있는 망고와 함께 즐기는 제주바다망고레이에서 달콤한 망고와 함께즐거운 제주여행하세요~!...🍹망고레이(하귀본점)위치: 하귀9길 34, 애월해안도로 입구-영업시간: 10:00~18:00.🍹망고레이(함덕직영점)생망고와 수제코코넛아이스크림을 맛 볼 수 있는 곳!망고레이에서 다양하고 맛있는 디저트 만나보세요..#제주도맛집#제주여행#제주디저트카페 #제주도이색맛집#제주공항카페 #제주디저트 #조천읍카페#함덕해수욕장맛집#제주망고 #함덕해수욕장카페', '2020-07-06', '390', '', ['#제주도맛집', '#제주여행', '#제주디저트카페', '#제주도이색맛집', '#제주공항카페', '#제주디저트', '#조천읍카페', '#함덕해수욕장맛집', '#제주망고', '#함덕해수욕장카페']]]\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-6 인스타그램 크롤링\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# ① 크롬 브라우저 열기\n",
    "#driver = webdriver.Chrome('D:/MyClass/Python/eAnalysisExample/2_제주맛집_크롤링_지도/webdriver/chromedriver.exe') \n",
    "driver = webdriver.Chrome(webdriverpath)\n",
    "\n",
    "# ② 인스타그램 검색페이지 URL 만들기\n",
    "word = \"제주도맛집\"    #검색어\n",
    "url = insta_searching(word)\n",
    "\n",
    "# ③ 검색페이지 접속하기\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# ④ 첫 번째+ 게시글 열기\n",
    "select_first(driver)\n",
    "login(driver)\n",
    "select_first(driver)\n",
    "# ⑤ 비어있는 변수(results)만들기\n",
    "results = [ ]\n",
    "\n",
    "\n",
    "# ⑥→⑦→⑧ 여러 게시물 수집하기\n",
    "target = 5      # 크롤링할 게시글 수 : 우선은 5개 하고 실제적으로 50개\n",
    "for i in range(target):\n",
    "    data = get_content(driver)    # 게시글 정보 가져오기\n",
    "    results.append(data)\n",
    "    move_next(driver)\n",
    "\n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-7 크롤링 결과 저장하기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['content','data','like','place','tags']\n",
    "results_df.to_excel('./files/3_1_crawling_jejudoMatJip.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.8 여러 엑셀 파일의 중복을 제거한 후 통합 저장\n",
    "\n",
    "인스타그램에서 여러 개의 키워드로 검색하거나 어러 번에 걸쳐 데이터를 수집하는 경우가 많다.\n",
    "\n",
    "동일한 게시물을 중복으로 수집되는 경우 중복을 제거해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-8 여러 개의 저장파일 통합하기\n",
    "jeju_insta_df = pd.DataFrame( [ ] )\n",
    "\n",
    "folder = './files/'\n",
    "\n",
    "# f_list = ['3_1_crawling_jejudoMatJip.xlsx', '3_1_crawling_jejudoGwanGwang.xlsx', '3_1_crawling_jejuMatJip.xlsx', '3_1_crawling_jejuYeoHang.xlsx']\n",
    "f_list = ['3_1_crawling_jejuYeoHang.xlsx', '3_1_crawling_jejudoGwanGwang.xlsx','3_1_crawling_jejuYeoHang.xlsx','3_1_crawling_jejuMatJip.xlsx']\n",
    "\n",
    "for fname in f_list:\n",
    "    fpath = folder + fname\n",
    "    temp = pd.read_excel(fpath)\n",
    "    jeju_insta_df = jeju_insta_df.append(temp)\n",
    "\n",
    "jeju_insta_df.columns =['content','data','like','place','tags']\n",
    "\n",
    "# ???? jeju_insta_df.columns  왜 7개 이지???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 예제 4-9 중복 데이터 제거하고 저장하기\n",
    "jeju_insta_df.drop_duplicates(subset = [ \"content\"] , inplace = True)\n",
    "jeju_insta_df.to_excel('./files/3_1_crawling_raw.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
