{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[도서]  [데이터실무분석 with파이썬 예제](https://wikibook.co.kr/playwithdata/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 인스타그램 크롤링 \n",
    "\n",
    "### (1) selenium 설치 \n",
    "   \n",
    "    + pip install selenium\n",
    "    \n",
    "    + 웹드라이버 다운로드\n",
    "        http://chromedriver.chromium.org/downloads\n",
    "        chromedirver_win32.zip 파일 다운로드 받고 압축풀기\n",
    "\n",
    "        설치된 크롬 버전과 맞는 버전을 다운로드 해야 한다.\n",
    "        \n",
    "        \n",
    "---        \n",
    "[참고] 사이트 변경으로 인해 데이타를 못 가져올 수도 있다        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 인스타그램 검색 결과 URL을 만들어서 접속하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-1 인스타그램 검색결과 URL을 만드는 함수\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriverpath = 'D:/python-workspace/PythonBasic/webdriver/chromedriver.exe' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 첫 번째 게시글 열기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-3 HTML에서 첫번째 게시글 찾아 클릭하기\n",
    "def select_first(driver):\n",
    "    \n",
    "    driver.implicitly_wait(10) # 로딩 속도 때문에 클릭이벤트를 못하기에 추가 ( 상황에 따라 실행되었다 안되었다 함 )\n",
    "    \n",
    "    first = driver.find_element_by_css_selector(\"div._9AhH0\")\n",
    "    first.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 게시글 정보 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-4 게시글 정보 가져오기\n",
    "import re\n",
    "\n",
    "def get_content(driver):\n",
    "    # ① 현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    # ② 본문 내용 가져오기\n",
    "    try:\n",
    "        content = soup.select('div.C4VMK > span')[0].text\n",
    "    except:\n",
    "        content = ' '\n",
    "    # ③ 본문 내용에서 해시태그 가져오기(정규식 활용)\n",
    "    tags = re.findall(r'#[^\\s#,\\\\]+', content)  \n",
    "    # ④ 작성일자 정보 가져오기\n",
    "    date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10]\n",
    "    print('get_content 확인', date)\n",
    "    # ⑤ 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('div.Nm9Fw > button')[0].text[4:-1]   \n",
    "    except:\n",
    "        like = 0\n",
    "    # ⑥ 위치정보 가져오기\n",
    "    try: \n",
    "        place = soup.select('div.M30cS')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "    # ⑦ 수집한 정보 저장하기\n",
    "    data = [content, date, like, place, tags]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 다음 게시글 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-5 다음 게시글 열기\n",
    "def move_next(driver):\n",
    "\n",
    "    driver.implicitly_wait(10) # 로딩 속도 때문에 클릭이벤트를 못하기에 추가 ( 상황에 따라 실행되었다 안되었다 함 )\n",
    "    \n",
    "    right = driver.find_element_by_css_selector ('a.coreSpriteRightPaginationArrow')\n",
    "    right.click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 여러 게시글 정보 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "#------------------------------------------------------------------------------------\n",
    "def readp():\n",
    "    f = open(\"D:/python-workspace/PythonBasic/webdriver/a.txt\")\n",
    "    a = f.readline()\n",
    "    return a\n",
    "def login(driver):\n",
    "    driver.find_elements_by_css_selector('label.f0n8F > input')[0].send_keys('010-3303-1995')\n",
    "    driver.find_elements_by_css_selector('label.f0n8F > input')[1].send_keys(readp())\n",
    "    driver.find_elements_by_css_selector('button.sqdOP > div.Igw0E')[0].click()\n",
    "    time.sleep(3)\n",
    "    driver.find_elements_by_css_selector('button.sqdOP')[0].click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_content 확인 2020-06-17\n",
      "get_content 확인 2020-07-01\n",
      "get_content 확인 2020-06-16\n",
      "get_content 확인 2020-06-24\n",
      "get_content 확인 2020-06-17\n",
      "[['제주 #사라오름 산정호수🏞.\"제주도민이 알려주는 진짜 제주도\" @jejumini 입니다..백록담에 버금간다는 산정호수가 있는 장소..오름중에 가장 높은 곳이며, 백록담을 오르는 성판악 코스중간에 사라오름으로 향하는 갈림길이 나옵니다 (왕복4시간 코스)..평소에는 호수라 말하기 무색할 만큼 말라 있지만, 장마 태풍등 기록적 폭우가 내리면 만수가 되어 폭우가 선사한 장관을 보실 수 있어요 (1년에 1-2번뿐 기회가 없음)..지난주부터 시작된 장마로 산정호수를 볼 수 있지 않을까 기대했지만 생각보다 마른 장마로 이번은 아쉽게도 만수까진 안될거 같네요(위 사진,영상 작년 가을 촬영본)...유네스코 자연 유산에 추가된 산정호수로 달려가세요🐎...[추천코스: 사라오름 > #제주돈아서귀포점 (흑돼지) > #서귀다원 ]....🔹제주여행 코스 무료로 도움 드려요 (DM주세요)🔹...(제주미니 모든 포스팅은 핸드폰으로 촬영📱)---------------------------------------------------------------[ 제주미니 투어 - 무조건 무료❗ ].※일시 : 매주 토요일 (평일 진행 예정)※코스시간 : 13:00 ~ 18:00[히든스팟] > [콜라보업체] > [카페] > [히든스팟]※인원 : 15명 (뚜벅님 4명, 차량11명 )※자격 : 팔로워 누구나 (도민부터~여행객까지)※신청방법 : DM ( 내용: 인원/날짜/차량유무 )- 투어참가 조건 없으며, 사연 보내지 말아주세요- 우천시 투어 취소.렌트한 차량으로 제 차량을 따라 다니면서 함께 구경하시면 되구요, 뚜벅이 4분(명)까지 제 차량에 탑승 가능합니다^^..<제주미니 콜라보 업체 : 참가자 무료 이용>※ 한라산 소주 : 제주미니 에디션 한라산 소주※ 제주라프(LAF) : 짚라인, 야간전시, 족욕.※ 씨에스호텔 : 브런치 식사 & 피크닉 투어.※ 김녕요트투어 : 최고급 요트 - 돌고래 생태 투어※ 더클리프 (썬셋클리프) : 매월 음료 100잔 무료※ 우픽스냅 : 박상우 사진작가 스냅투어※ 원앤온리 : 프리미엄 브런치 투어(매주 콜라보 업체는 변경 됩니다 - 일정 확인해 주세요).🔹️제주미니무료 투어일정🔹️(최신게시글을 통해 코스와 일정을 확인하세요)..※ 매주 토요일 진행(위 일정 안나온 투어 사전예약 불가)...( DM으로 신청 주시면 됩니다^^ 인원/날짜/차량유무 )-모든 분들께 당첨/마감 답장 다 해드려요---------------------------------------------------------------...#제주미니 #jejumini', '2020-06-17', '37,868', '한라산 사라오름', ['#사라오름', '#제주돈아서귀포점', '#서귀다원', '#제주미니', '#jejumini']], ['다양한 해산물과 환상적인 바다뷰를 보면서 식사를 할수 있는 #성산일출봉 #코코마마.계절마다 특색있는 음료수도 판매하고 있고네이버예약시 보다 편리하게 이용 가능하네요⠀🦀제주 서귀포시 성산읍 일출로 258-11 성산🦀064-782-5569🦀코코마마⠀.#성산맛집 #성산일출봉맛집 #서귀포맛집#제주맛집 #제주도맛집 #애월맛집 #우도맛집#제주도여행 #월정리카페 #오설록맛집#산방산맛집 #모슬포맛집 #서귀포카페', '2020-07-01', 0, '', ['#성산일출봉', '#코코마마.계절마다', '#성산맛집', '#성산일출봉맛집', '#서귀포맛집', '#제주맛집', '#제주도맛집', '#애월맛집', '#우도맛집', '#제주도여행', '#월정리카페', '#오설록맛집', '#산방산맛집', '#모슬포맛집', '#서귀포카페']]]\n"
     ]
    }
   ],
   "source": [
    "# 예제 4-6 인스타그램 크롤링\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# ① 크롬 브라우저 열기\n",
    "#driver = webdriver.Chrome('D:/MyClass/Python/eAnalysisExample/2_제주맛집_크롤링_지도/webdriver/chromedriver.exe') \n",
    "driver = webdriver.Chrome(webdriverpath)\n",
    "\n",
    "# ② 인스타그램 검색페이지 URL 만들기\n",
    "word = \"우도맛집\"    #검색어\n",
    "url = insta_searching(word)\n",
    "\n",
    "# ③ 검색페이지 접속하기\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# ④ 첫 번째+ 게시글 열기\n",
    "select_first(driver)\n",
    "login(driver)\n",
    "select_first(driver)\n",
    "# ⑤ 비어있는 변수(results)만들기\n",
    "results = [ ]\n",
    "\n",
    "\n",
    "# ⑥→⑦→⑧ 여러 게시물 수집하기\n",
    "target = 5      # 크롤링할 게시글 수 : 우선은 5개 하고 실제적으로 50개\n",
    "for i in range(target):\n",
    "    data = get_content(driver)    # 게시글 정보 가져오기\n",
    "    results.append(data)\n",
    "    move_next(driver)\n",
    "\n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-7 크롤링 결과 저장하기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['content','data','like','place','tags']\n",
    "results_df.to_excel('./files/Instagram_Crawling/4_1_crawling_result.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
